# ğŸ”‹ EMT RL PROJECT CONFIG
# Energy Management with Reinforcement Learning

# ğŸ  Environment Parameters
environment:
  battery:
    capacity_kwh: 5000
    initial_soc: 0.8
    min_soc: 0.1
    max_soc: 0.9
    max_power_kw: 1000      # Batarya gÃ¼cÃ¼ 1000kW'a gÃ¼ncellendi
    efficiency: 0.92
  grid:
    max_power_kw: 10000     # Åebeke kapasitesi 10000kW'a gÃ¼ncellendi

# ğŸ’° Price Configuration
prices:
  night:
    hours: [22, 23, 0, 1, 2, 3, 4, 5, 6, 7]
    price: 0.12123
    category: "low"
  day: 
    hours: [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]
    price: 0.20428
    category: "medium"
  peak:
    hours: [18, 19, 20, 21]
    price: 0.30867
    category: "high"

# ğŸ¤– Reward Parameters
reward:
  # Temel cezalar
  unmet_load_penalty: -1000.0       # KarÅŸÄ±lanamayan yÃ¼k iÃ§in kW baÅŸÄ±na ceza (EN KRÄ°TÄ°K)
  soc_penalty_coef: -2000.0          # SOC limit aÅŸÄ±mÄ±nda, aÅŸÄ±lan % baÅŸÄ±na ceza
  
  # Stratejik cezalar
  price_penalty_coef:               # Gereksiz ÅŸebeke kullanÄ±mÄ± iÃ§in fiyat seviyesine gÃ¶re ceza katsayÄ±larÄ±
    low: -0.01
    medium: -0.05
    high: -0.1
  
  unused_penalty_coef: -50         # Ä°sraf edilen yenilenebilir enerji iÃ§in kW baÅŸÄ±na ceza
  
  cheap_energy_missed_penalty_coef: -50.0 # Ucuz ÅŸarj fÄ±rsatÄ± kaÃ§Ä±rma cezasÄ± (SOC farkÄ± * katsayÄ±)

# ğŸ¤– Training Parameters
training:
  # Model parameters
  learning_rate: 0.001
  batch_size: 128
  gamma: 0.99
  
  # Training parameters
  total_timesteps: 1000000
  save_freq: 100000
  
  # Exploration parameters
  exploration:
    entropy_coef: 0.05
    exploration_fraction: 0.3
    
  # Episode parameters
  episodes: 100
  episode_length: 8760

# ğŸ“Š Monitoring
monitoring:
  save_frequency: 10
  plot_frequency: 5
  tensorboard_log: "./logs"

# ğŸ“ Data Paths
data:
  load_file: "data/synthetic_load_itu.csv"
  wind_file: "data/sim_wind_gen_result.csv" 
  solar_file: "data/sim_solar_gen_result.csv" 